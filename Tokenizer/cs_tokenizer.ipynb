{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1414045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cbdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import sys\n",
    "from typing import List, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0c9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DOTNET_ROOT\"] = r\"C:\\Program Files\\dotnet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f516e",
   "metadata": {},
   "source": [
    "Магия для того, чтобы clr импортнулась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a31c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clr_loader import get_coreclr\n",
    "from pythonnet import set_runtime\n",
    "config_file_path: str = r\"C:\\Users\\Maksim\\Obfuscation\\Tokenizer\\pspython.runtimeconfig.json\"\n",
    "rt = get_coreclr(runtime_config=config_file_path)\n",
    "set_runtime(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa61f544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RuntimeInfo(kind='CoreCLR', version='<undefined>', initialized=True, shutdown=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonnet.get_runtime_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab522fde",
   "metadata": {},
   "source": [
    "Подгрузка библиотек DLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3b4112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<System.Reflection.RuntimeAssembly object at 0x000001EB41BF5340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clr \n",
    "import System \n",
    "# from System import Environment\n",
    "# from System import Reflection\n",
    "\n",
    "psHome = r\"C:\\Program Files\\PowerShell\\7\\\\\"\n",
    "mmi = psHome + r'Microsoft.Management.Infrastructure.dll'\n",
    "clr.AddReference(mmi)\n",
    "# from Microsoft.Management.Infrastructure import *\n",
    "\n",
    "full_filename = psHome + r\"System.Management.Automation.dll\"\n",
    "clr.AddReference(full_filename)\n",
    "# from System.Management.Automation import *\n",
    "# from System.Management.Automation.Language import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f338bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\Maksim\\source\\repos\\PSFeatureExtractorLibrary\\PSFeatureExtractorLibrary\\bin\\Debug\\net6.0\")\n",
    "clr.AddReference(\"PSFeatureExtractorLibrary\")\n",
    "import PSFeatureExtractorLibrary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8147013",
   "metadata": {},
   "source": [
    "Захардкоженные переменные для скорости работы токенизатора c#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b68d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = [PSFeatureExtractorLibrary.GroupedArrayElementRangeCounts.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.ArrayElementMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.GroupedAssignmentStatements.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.GroupedAstTypes.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.GroupedBinaryExpressionOperators.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.CmdletMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.CommandParameterNameMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.CommentMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.ConvertExpressionMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.FunctionNameMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.IntegerAndDoubleMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.InvocationOperatorInvokedObjectMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.LineByLineMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.MemberArgumentMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.MemberMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.StringMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.TypeConstraintMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.TypeExpressionMetrics.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.GroupedUnaryExpressionOperators.AnalyzeAst,\n",
    "                PSFeatureExtractorLibrary.VariableNameMetrics.AnalyzeAst\n",
    "]\n",
    "\n",
    "length_list = [22, 312, 14, 152, 104, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 26, 312]\n",
    "length_cumulative_list = np.cumsum(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11adbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_CS(command: str, methods_list, length_cumulative_list) -> List[float]:\n",
    "    ast, token, parseerror = System.Management.Automation.Language.Parser.ParseInput(command)\n",
    "    \n",
    "    if (len(parseerror)!=0):\n",
    "        return False\n",
    "    \n",
    "    total_features: int = length_cumulative_list[-1]\n",
    "    res_list = np.zeros(total_features, dtype=\"float64\")\n",
    "    \n",
    "    first_index = 0\n",
    "    last_index = length_cumulative_list[0]\n",
    "    \n",
    "    for i in range(len(methods_list)):\n",
    "        last_index = length_cumulative_list[i]\n",
    "        command_handling_result = methods_list[i](ast)\n",
    "        res_list[first_index:last_index] = list(command_handling_result.Values)\n",
    "        first_index = last_index\n",
    "\n",
    "    return list(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb2171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_CS_with_features(command: str, methods_list, length_cumulative_list) -> Dict[str, List[Union[str, int, float]]]:\n",
    "    ast, token, parseerror = System.Management.Automation.Language.Parser.ParseInput(command)\n",
    "    \n",
    "    if (len(parseerror)!=0):\n",
    "        return False\n",
    "    \n",
    "    total_features: int = length_cumulative_list[-1]\n",
    "    res_list = np.zeros(total_features, dtype=\"float64\")\n",
    "    feature_names = [''] * total_features\n",
    "    \n",
    "    first_index = 0\n",
    "    last_index = length_cumulative_list[0]\n",
    "    \n",
    "    for i in range(len(methods_list)):\n",
    "        last_index = length_cumulative_list[i]\n",
    "        command_handling_result = methods_list[i](ast)\n",
    "        res_list[first_index:last_index] = list(command_handling_result.Values)\n",
    "        feature_names[first_index:last_index] = list(command_handling_result.Keys)            \n",
    "        first_index = last_index\n",
    "\n",
    "    return {\"result_keys\": feature_names, \"result_values\": list(res_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a75d1",
   "metadata": {},
   "source": [
    "Токенизатор PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cced8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_PS(command: str):\n",
    "    script_feature = f'Get-RvoFeatureVector -ScriptBlock {{{command}}}'\n",
    "    res_feature = subprocess.run([\"pwsh\", \"-Command\", script_feature], capture_output=True)\n",
    "    output_bytes = res_feature.stdout\n",
    "    output_str = output_bytes.decode(\"utf-8\")\n",
    "    try:\n",
    "        output_dict = json.loads(output_str)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "    \n",
    "    return list(output_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c21f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "command = \"cmd   /c   \"\"set  tic=Get-ChildItem -path HKLM:\\SYSTEM\\CurrentControlSet\\Services\\SNMP -Recurse&&C:\\WINDOWS\\system32\\mshta  VBScript:CreateObject(\"\"WScript.Shell\"\").Run(\"\"powershell      ^& ( '{0}{3}{1}{2}{4}{5}' -f'I','k','e-','nvo','Expressio','n' ) ( ( .('GI'  ) ( '{1}{0}'-f 'c','env:ti') ).'Value' )\"\",(23-1-21),True)(Window.Close)\"\"\"\n",
    "# res_PS = tokenizer_PS(command)\n",
    "res_CS = tokenizer_CS(command, methods_list, length_cumulative_list)\n",
    "print(res_CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff5672a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131072\n",
      "9223372036854775807\n"
     ]
    }
   ],
   "source": [
    "print(csv.field_size_limit())\n",
    "print(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22d8623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_field_size_limit() -> None:\n",
    "    maxInt = sys.maxsize\n",
    "    while True:\n",
    "        # decrease the maxInt value by factor 10 \n",
    "        # as long as the OverflowError occurs.\n",
    "        try:\n",
    "            csv.field_size_limit(maxInt)\n",
    "            break\n",
    "        except OverflowError:\n",
    "            maxInt = int(maxInt/10)\n",
    "            \n",
    "        \n",
    "set_field_size_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f716ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename: str) -> List[str]:\n",
    "    with open(filename, encoding=\"UTF8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb0d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(filename: str, row: List[Union[str, int, float]]) -> None:\n",
    "    with open(filename, mode='a', newline='', encoding=\"UTF8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be73a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(input_filename: str, output_filename: str, wrong_command_filename: str, required_columns_indexes: List[int] = None) -> int:\n",
    "    generator = get_data(input_filename)\n",
    "    all_column_names: List[str] = next(generator)\n",
    "    \n",
    "    if required_columns_indexes is None:\n",
    "        required_columns_indexes = list(range(len(all_column_names)))\n",
    "    required_columns: List[str] = [all_column_names[i] for i in required_columns_indexes]  \n",
    "    # ['command_clear', 'command_obfuscated', 'obfuscated']\n",
    "    \n",
    "    row_number: int = 2\n",
    "    is_added_header: bool = False\n",
    "    proccessed_values: List[float]\n",
    "        \n",
    "    while True:\n",
    "        if not row_number % 500: \n",
    "            print(f\"Row №{row_number} is proccessed.\\n\")\n",
    "        row: List[str] = next(generator, None)\n",
    "        if row is None:\n",
    "            print(\"Dataset proccessing is completed succesfully!\")\n",
    "            break\n",
    "\n",
    "        clear_command, obfuscated_command, target_value = [row[i] for i in required_columns_indexes]\n",
    "        target_value = int(target_value)\n",
    "\n",
    "        proccessing_result = tokenizer_CS(obfuscated_command, methods_list, length_cumulative_list) if is_added_header else tokenizer_CS_with_features(obfuscated_command, methods_list, length_cumulative_list)\n",
    "\n",
    "        if not proccessing_result:\n",
    "            values = [row_number, clear_command, obfuscated_command, target_value]\n",
    "            write_csv(filename=wrong_command_filename, row=values)\n",
    "            row_number += 1\n",
    "            continue\n",
    "\n",
    "        if not is_added_header:  # inserting header\n",
    "            features, proccessed_values = proccessing_result[\"result_keys\"], proccessing_result[\"result_values\"]\n",
    "            output_header: List[str] = required_columns[:-1] + features + [required_columns[-1]]\n",
    "            write_csv(filename=output_filename, row=output_header)\n",
    "            is_added_header = True\n",
    "        else:\n",
    "            proccessed_values = proccessing_result\n",
    "\n",
    "        row_values: List[Union[str, int, float]] = [clear_command, obfuscated_command] + proccessed_values + [target_value]\n",
    "        write_csv(filename=output_filename, row=row_values)\n",
    "        row_number += 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148a7cd",
   "metadata": {},
   "source": [
    "### Processing sourse powershell dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb129c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME: str = r\"D:\\Obfuscation\\data\\datasets\\POWERSHELL_DATASET.csv\"\n",
    "OUTPUT_FILENAME: str = r\"D:\\Obfuscation\\data\\datasets\\TOKENIZER_DATASET.csv\"\n",
    "WRONG_COMMAND_FILENAME: str = r\"D:\\Obfuscation\\data\\datasets\\WRONG_COMMANDS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eafba238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row №500 is proccessed.\n",
      "\n",
      "Row №1000 is proccessed.\n",
      "\n",
      "Row №1500 is proccessed.\n",
      "\n",
      "Row №2000 is proccessed.\n",
      "\n",
      "Row №2500 is proccessed.\n",
      "\n",
      "Row №3000 is proccessed.\n",
      "\n",
      "Row №3500 is proccessed.\n",
      "\n",
      "Row №4000 is proccessed.\n",
      "\n",
      "Row №4500 is proccessed.\n",
      "\n",
      "Row №5000 is proccessed.\n",
      "\n",
      "Row №5500 is proccessed.\n",
      "\n",
      "Row №6000 is proccessed.\n",
      "\n",
      "Row №6500 is proccessed.\n",
      "\n",
      "Row №7000 is proccessed.\n",
      "\n",
      "Row №7500 is proccessed.\n",
      "\n",
      "Row №8000 is proccessed.\n",
      "\n",
      "Row №8500 is proccessed.\n",
      "\n",
      "Row №9000 is proccessed.\n",
      "\n",
      "Row №9500 is proccessed.\n",
      "\n",
      "Row №10000 is proccessed.\n",
      "\n",
      "Row №10500 is proccessed.\n",
      "\n",
      "Row №11000 is proccessed.\n",
      "\n",
      "Row №11500 is proccessed.\n",
      "\n",
      "Row №12000 is proccessed.\n",
      "\n",
      "Row №12500 is proccessed.\n",
      "\n",
      "Row №13000 is proccessed.\n",
      "\n",
      "Row №13500 is proccessed.\n",
      "\n",
      "Row №14000 is proccessed.\n",
      "\n",
      "Row №14500 is proccessed.\n",
      "\n",
      "Row №15000 is proccessed.\n",
      "\n",
      "Row №15500 is proccessed.\n",
      "\n",
      "Row №16000 is proccessed.\n",
      "\n",
      "Row №16500 is proccessed.\n",
      "\n",
      "Row №17000 is proccessed.\n",
      "\n",
      "Row №17500 is proccessed.\n",
      "\n",
      "Row №18000 is proccessed.\n",
      "\n",
      "Row №18500 is proccessed.\n",
      "\n",
      "Row №19000 is proccessed.\n",
      "\n",
      "Row №19500 is proccessed.\n",
      "\n",
      "Row №20000 is proccessed.\n",
      "\n",
      "Row №20500 is proccessed.\n",
      "\n",
      "Row №21000 is proccessed.\n",
      "\n",
      "Row №21500 is proccessed.\n",
      "\n",
      "Row №22000 is proccessed.\n",
      "\n",
      "Row №22500 is proccessed.\n",
      "\n",
      "Row №23000 is proccessed.\n",
      "\n",
      "Row №23500 is proccessed.\n",
      "\n",
      "Row №24000 is proccessed.\n",
      "\n",
      "Row №24500 is proccessed.\n",
      "\n",
      "Row №25000 is proccessed.\n",
      "\n",
      "Row №25500 is proccessed.\n",
      "\n",
      "Row №26000 is proccessed.\n",
      "\n",
      "Row №26500 is proccessed.\n",
      "\n",
      "Row №27000 is proccessed.\n",
      "\n",
      "Row №27500 is proccessed.\n",
      "\n",
      "Row №28000 is proccessed.\n",
      "\n",
      "Row №28500 is proccessed.\n",
      "\n",
      "Row №29000 is proccessed.\n",
      "\n",
      "Row №29500 is proccessed.\n",
      "\n",
      "Row №30000 is proccessed.\n",
      "\n",
      "Row №30500 is proccessed.\n",
      "\n",
      "Row №31000 is proccessed.\n",
      "\n",
      "Row №31500 is proccessed.\n",
      "\n",
      "Row №32000 is proccessed.\n",
      "\n",
      "Dataset proccessing is completed succesfully!\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tokenize_data(\n",
    "    input_filename=INPUT_FILENAME,\n",
    "    required_columns_indexes=[0, 1, 7],\n",
    "    output_filename=OUTPUT_FILENAME,\n",
    "    wrong_command_filename=WRONG_COMMAND_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc651d",
   "metadata": {},
   "source": [
    "### Processing poor obfuscated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc13ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/POOR_OBFUSCATED_DATASET.csv\"\n",
    "OUTPUT_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/POOR_OBFUSCATED_TOKENIZER_DATASET.csv\"\n",
    "WRONG_COMMAND_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/POOR_OBFUSCATED_WRONG_COMMANDS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cbb9c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row №500 is proccessed.\n",
      "\n",
      "Row №1000 is proccessed.\n",
      "\n",
      "Row №1500 is proccessed.\n",
      "\n",
      "Dataset proccessing is completed succesfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_data(\n",
    "    input_filename=INPUT_FILENAME,\n",
    "    output_filename=OUTPUT_FILENAME,\n",
    "    wrong_command_filename=WRONG_COMMAND_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857ff62",
   "metadata": {},
   "source": [
    "### Processing dataset containing commands with cyrillic symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aee4851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/CYRILLIC_DATASET.csv\"\n",
    "OUTPUT_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/CYRILLIC_TOKENIZER_DATASET.csv\"\n",
    "WRONG_COMMAND_FILENAME: str = r\"D:/Obfuscation/data/datasets/additional/data/CYRILLIC_WRONG_COMMANDS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bcc7f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset proccessing is completed succesfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_data(\n",
    "    input_filename=INPUT_FILENAME,\n",
    "    output_filename=OUTPUT_FILENAME,\n",
    "    wrong_command_filename=WRONG_COMMAND_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f06fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
